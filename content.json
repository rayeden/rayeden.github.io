{"meta":{"title":"One-Way Street","subtitle":"One-Way Street","description":"Keep moving with no regret.","author":"理想主义和宅","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"关于序列化.md","slug":"关于序列化","date":"2018-07-25T09:14:27.000Z","updated":"2018-07-25T14:42:43.940Z","comments":true,"path":"2018/07/25/关于序列化/","link":"","permalink":"http://yoursite.com/2018/07/25/关于序列化/","excerpt":"Java序列化学习。","text":"Java序列化学习。 几个问题什么是序列化？ 序列化是指把对象按照一定的编码协议转化\b\b一串有序的二进制字节流，反序列化是指把这串二进制字节流恢复成对象。通常用于存储，网络传输或远程服务调用(RMI)。 为什么要做序列化（Java）？ 首先，序列化可以实现持久化，通过把对象转化成二进制字节流保存到文件。其次，序列化可以实现在网络传输字节流，实现进程间的远程通信（RPC框架，Dubbo）。 Java中的序列化是怎样的？ Java类可以通过实现Serializable或Externalizable接口，标记对象为可序列化。中Serializable是空接口，仅作为标记，\b可以配合transient关键字排除不需要序列化的\b域。也可以通过直接在类中重写writeObject()和readObject()方法定制序列化。而Externalizable则是需要强制实现writeExternal()和readExternal()方法定制序列化。 Serializable接口没有方法，其存在的意义？ \b仅作为序列化标记。当编译器检测到这个标记接口，会自动做序列化处理。Serializable接口提供Java默认的序列化机制，如果不使用它，就只能用Externalizable接口，自定义序列化机制。 SerialVersionUID的作用是什么，有和没有的区别？ SerialVersionUID是为了解决序列化的版本兼容性问题，它是由类名，成员方法和变量域等类信息计算得出的64位哈希值。在\b执行反序列化时会对这个值做校验，如果不一样，就无法反序列化成对象。 不修改类，反序列化 增加数据，反序列化 删除数据，反序列化 不显示声明UID 反序列化成功 InvalidClassException InvalidClassException 显示声明UID 反序列化成功 向上兼容，忽略新增数据 向下兼容，丢失的数据保持默认值 如果实现不序列化类中的某些数据？ 标记为trantient或者static。 \b如果类中存在对象的类没有被序列化会发生什么？ \b抛出运行时异常\b，NotSerializableException。 \b如何自己实现序列化？ Serializable 可以在实现Serializable接口重写writeObject()方法和readObject()方法。这是直接在类中复写的方法，为了防止它们被继承和覆盖，所以声明为private。只要实现了这两个方法，JVM在序列化时会优先调用它们（通过反射检测），而不是ObjectOutputStream()和ObjectInputStream()类中的方法。 private void writeObject(ObjectOutputStream stream) private void readObject(ObjectInputStream stream) Externalizable 实现Externalizable并实现writeExternal(ObjectOutput out)和readExternal(ObjectInput in)自定义序列化。 假设有一个类已经被序列化且持久化，此时新增一个域，反序列化时会发生什么？ 这要看它是否被显示声明了SerialVersionUID。如果没有被显示声明，那么在执行前后这个类的SerialVersionUID都会根据其方法和属性重新计算，修改后计算的结果必然不一样，会导致InvalidClassException。如果有显示声明的SerialVersionUID，就能正常反序列化。 如果transient的域不会被序列化，那么他们的存在的意义是什么？ 可以用在比如用户密码这种不想被恢复的隐私数据。","categories":[],"tags":[{"name":"基础，Java","slug":"基础，Java","permalink":"http://yoursite.com/tags/基础，Java/"}]},{"title":"ignite固化内存(持久化)示例","slug":"ignite固化内存-持久化-示例","date":"2018-04-12T11:14:08.000Z","updated":"2018-06-29T15:29:05.762Z","comments":true,"path":"2018/04/12/ignite固化内存-持久化-示例/","link":"","permalink":"http://yoursite.com/2018/04/12/ignite固化内存-持久化-示例/","excerpt":"","text":"文章源码 – c2_ignitePersistence 环境ignite版本: v_2.3.0 现在已经更新到v_2.4.0，增加了不少新特性，然而最低要求jdk8，所以暂时项目上不考虑。 开发环境：参考上一篇文章 – ignite安装和SpringData集成 持久化特性原生持久化 存储：ignite所有的数据和索引都是存放在堆外内存，启动持久化之后，ignite默认会分配最大内存的20%存储原有数据。为什么只用20%？因为ignite会把数据都持久化到磁盘文件并默认开启LRU缓存策略，内存中只保留热数据。 不开启持久化 开启持久化 默认无内存替换策略 默认LRU替换 所有cache都在ignite内存区里操作 指定持久化的cache会被分配指定大小的区域并且只在这片区域里操作 集群启动后默认激活 集群启动后默认未激活，需要手动activate 集群重启后数据丢失 集群重启并激活后可以直接从持久化文件读取数据，同时热数据加载到cache 示例测试说明ignite安装和SpringData集成里用PaperVO作为实体存储，本例新增AuthorVO做第二个存储实体，并且开启AuthorCache的持久化特性。本例以单节点server模式启动ignite，分别向PaperCache和AuthorCache存储数据，然后关闭ignite服务。重启ignite服务后，激活节点，再分别从PaperCache和AuthorCache取出数据。 实验结果：PaperCache为空，取不出任何数据；AuthorCache数据被持久化到磁盘，重启服务后依然可以获取之前的数据。 xml配置 基于上一篇xml配置的修改 以server模式启动。 开启持久化并配置ds.cfg，配置一个DataRegionConfiguration。 新增AuthorCache，并在配置里注入dataRegionName属性。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 扫描Repository包 --&gt; &lt;context:component-scan base-package=\"com.xhtc.ignite\"/&gt; &lt;bean id=\"igniteClient\" class=\"com.xhtc.ignite.IgniteClient\"&gt; &lt;property name=\"igniteConfiguration\" ref=\"igniteConfig\"/&gt; &lt;/bean&gt; &lt;bean id=\"igniteConfig\" class=\"org.apache.ignite.configuration.IgniteConfiguration\"&gt; &lt;!-- server模式启动 --&gt; &lt;!--&lt;property name=\"clientMode\" value=\"true\"/&gt;--&gt; &lt;!-- 配置客户端节点名称 --&gt; &lt;property name=\"igniteInstanceName\" value=\"igniteStart\"/&gt; &lt;!-- 客户端关闭metrics日志打印(value类型long 设置60*1000L即为1分钟刷新一次metrics日志，设置为0即关闭) --&gt; &lt;!--&lt;property name=\"metricsLogFrequency\" value=\"0\"/&gt;--&gt; &lt;!-- server重启时客户端自动重连(value时间内服务端若重启客户端会自动重连)--&gt; &lt;property name=\"networkTimeout\" value=\"1000000\"/&gt; &lt;!-- 配置内存数据网格 --&gt; &lt;property name=\"cacheConfiguration\"&gt; &lt;list&gt; &lt;ref bean=\"paperCache\"/&gt; &lt;!-- authorCache配置为持久化缓存 --&gt; &lt;ref bean=\"authorCache\"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 配置集群ip(静态) --&gt; &lt;property name=\"discoverySpi\" ref=\"discoverySpi\"/&gt; &lt;!-- 固化内存配置 --&gt; &lt;property name=\"dataStorageConfiguration\" ref=\"ds.cfg\"/&gt; &lt;property name=\"gridLogger\"&gt; &lt;bean class=\"org.apache.ignite.logger.log4j.Log4JLogger\"/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"authorCache\" class=\"org.apache.ignite.configuration.CacheConfiguration\"&gt; &lt;property name=\"name\" value=\"AuthorCache\"/&gt; &lt;property name=\"cacheMode\" value=\"REPLICATED\"/&gt; &lt;property name=\"indexedTypes\"&gt; &lt;list&gt; &lt;value&gt;java.lang.Long&lt;/value&gt; &lt;value&gt;com.xhtc.ignite.vo.AuthorVO&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- AuthorCache配置持久化 --&gt; &lt;property name=\"dataRegionName\" value=\"50MB_Region\"/&gt; &lt;/bean&gt; &lt;bean id=\"paperCache\" class=\"org.apache.ignite.configuration.CacheConfiguration\"&gt; &lt;!-- 数据网格名称，Repository注解使用 --&gt; &lt;property name=\"name\" value=\"PaperCache\"/&gt; &lt;!-- 缓存模式可以是PARTITIONED(分片)REPLICATED(主从复制) --&gt; &lt;property name=\"cacheMode\" value=\"REPLICATED\"/&gt; &lt;!-- 使用Ignite数据网格必须设置indexedTypes --&gt; &lt;property name=\"indexedTypes\"&gt; &lt;list&gt; &lt;value&gt;java.lang.Long&lt;/value&gt; &lt;value&gt;com.xhtc.ignite.vo.PaperVO&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"discoverySpi\" class=\"org.apache.ignite.spi.discovery.tcp.TcpDiscoverySpi\"&gt; &lt;property name=\"ipFinder\"&gt; &lt;bean class=\"org.apache.ignite.spi.discovery.tcp.ipfinder.vm.TcpDiscoveryVmIpFinder\"&gt; &lt;property name=\"addresses\"&gt; &lt;list&gt; &lt;value&gt;127.0.0.1:47500..47509&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"ds.cfg\" class=\"org.apache.ignite.configuration.DataStorageConfiguration\"&gt; &lt;property name=\"dataRegionConfigurations\"&gt; &lt;list&gt; &lt;bean class=\"org.apache.ignite.configuration.DataRegionConfiguration\"&gt; &lt;property name=\"name\" value=\"50MB_Region\"/&gt; &lt;!-- 开启持久化 --&gt; &lt;property name=\"persistenceEnabled\" value=\"true\"/&gt; &lt;!-- 初始化10m --&gt; &lt;property name=\"initialSize\" value=\"#&#123;10L * 1024 * 1024&#125;\"/&gt; &lt;!-- 最大50m --&gt; &lt;property name=\"maxSize\" value=\"#&#123;50L * 1024 * 1024&#125;\"/&gt; &lt;!-- 缓存替换策略为Random-2-LRU --&gt; &lt;property name=\"pageEvictionMode\" value=\"RANDOM_2_LRU\"/&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 以下三个参数可以配置持久化文件的路径 --&gt; &lt;!-- 数据和索引持久化存储路径(推荐SSD) --&gt; &lt;!--&lt;property name=\"storagePath\" value=\"\"/&gt;--&gt; &lt;!-- wal文件存储路径（HDD) --&gt; &lt;!--&lt;property name=\"walPath\" value=\"\"/&gt;--&gt; &lt;!-- wal文件归档路径（HDD) --&gt; &lt;!--&lt;property name=\"walArchivePath\" value=\"\"/&gt;--&gt; &lt;/bean&gt;&lt;/beans&gt; 单元测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;\"classpath:applicationContext-ignite.xml\"&#125;)public class IgnitePersistenceTest &#123; @Autowired private IgniteClient igniteClient; @Autowired private AuthorRepository authorRepository; @Autowired private PaperRepository paperRepository; private SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); //执行单元测试之前先启动ignite服务并激活（执行激活后需等待数秒） @Before public void setUp() throws Exception &#123; igniteClient.igniteInstance(); &#125; //执行persistenceTest之后只做关闭不删除，防止数据删除操作被写入WAL然后持久化到文件 @After public void tearDown() throws Exception &#123; igniteClient.destroy(); &#125; //分别向PaperCache和AuthorCache插入几条数据，结束程序，关闭ignite @Test public void persistenceTest() throws ParseException &#123; Map&lt;Long, PaperVO&gt; map = new HashMap&lt;&gt;(); Map&lt;Long, AuthorVO&gt; map2 = new HashMap&lt;&gt;(); PaperVO x_paper1 = PaperVO.PaperVOBuilder.aPaperVO().paperId(1L).author(\"xhtc\").title(\"x_paper1\") .school(\"hdu\").publicTime(sdf.parse(\"2015-3-1 15:30:30\")).build(); PaperVO x_paper2 = PaperVO.PaperVOBuilder.aPaperVO().paperId(2L).author(\"xhtc\").title(\"x_paper2\") .school(\"hdu\").publicTime(sdf.parse(\"2015-10-1 10:00:00\")).build(); map.put(1L, x_paper1); map.put(2L, x_paper2); AuthorVO author1 = AuthorVO.AuthorVOBuilder.anAuthorVO().name(\"xhtc\").identity(\"student\").age(25).school(\"hdu\").build(); AuthorVO author2 = AuthorVO.AuthorVOBuilder.anAuthorVO().name(\"jgy\").identity(\"teacher\").age(28).school(\"hdu\").build(); AuthorVO author3 = AuthorVO.AuthorVOBuilder.anAuthorVO().name(\"zjl\").identity(\"teacher\").age(35).school(\"hdu\").build(); map2.put(1L, author1); map2.put(2L, author2); map2.put(3L, author3); paperRepository.save(map); authorRepository.save(map2); List&lt;AuthorVO&gt; authorVOS = authorRepository.getAuthorVOByAgeBefore(30); assert authorVOS.size() == 2; System.out.println(authorVOS.size()); List&lt;PaperVO&gt; paperVOS = paperRepository.getByAuthor(\"xhtc\"); assert paperVOS.size() == 2; &#125; //重新启动ignite服务，ignite从持久化文件中恢复persistenceTest插入的AuthorCache的数据，但无法获取PaperCache @Test public void persistenceTest2() throws ParseException &#123; List&lt;AuthorVO&gt; authorVOS = authorRepository.getAuthorVOByAgeBefore(30); assert authorVOS.size() == 2; List&lt;PaperVO&gt; paperVOS = paperRepository.getByAuthor(\"xhtc\"); assert paperVOS.size() == 0; &#125;&#125; 其他代码补充AuthorVO 此处省略Builder()。1234567891011121314@Datapublic class AuthorVO &#123; @QuerySqlField private String name; @QuerySqlField private Integer age; @QuerySqlField private String school; @QuerySqlField private String identity; public static final class AuthorVOBuilder &#123; ... &#125;&#125; IgniteClient 一开始写客户端启动一直无法获取到数据，直到debug发现执行ignite.active(true)后要等待一段时间，再获取数据即成功。123456789101112131415161718192021222324252627282930@Configuration@EnableIgniteRepositories(basePackages = &#123;\"com.xhtc.ignite.repository\"&#125;)public class IgniteClient &#123; private IgniteConfiguration igniteConfiguration; public static Ignite ignite; public IgniteConfiguration getIgniteConfiguration() &#123; return igniteConfiguration; &#125; public void setIgniteConfiguration(IgniteConfiguration igniteConfiguration) &#123; this.igniteConfiguration = igniteConfiguration; &#125; //IgniteRepositoryBeanFactory指定要名为igniteInstance的Bean @Bean public Ignite igniteInstance() &#123; ignite = Ignition.start(igniteConfiguration); try &#123; //开启持久化的ignite服务（集群）启动后默认是未激活状态，需要手动激活 ignite.active(true); //激活需要一定时间，这里如果不等待一下马上SELECT的话会报集群未激活/激活失败的错误 Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; System.out.println(\"激活ignite集群超时 \" + e); &#125; return ignite; &#125; //本例需要保留缓存数据所以只做关闭操作，不删除数据 public void destroy() &#123; ignite.close(); &#125;&#125; AuthorRepository1234567@RepositoryConfig(cacheName = \"AuthorCache\")public interface AuthorRepository extends IgniteRepository&lt;AuthorVO, Long&gt; &#123; AuthorVO getAuthorVOByName(String name); @Query(\"SELECT * FROM AuthorVO WHERE age &lt; ?\") List&lt;AuthorVO&gt; getAuthorVOByAgeBefore(Integer age);&#125; 待测试的问题（记录） 给特定cache组分配固定大小的内存后，ignite会自动开启缓存替换策略，如果用户的数据是多条目的，是否会导致数据部分丢失的情况？ 开启持久化后，ignite服务（集群）激活所需的时间是否会和持久化文件的大小有关？ 如果把持久化的cache组分配到堆内，gc会对这片区域造成什么影响？ REPUBLICATED存储模式，多server的集群在重启节点后，rebalance会优先复制cache还是把持久化部分独立出来单独恢复？","categories":[{"name":"ignite","slug":"ignite","permalink":"http://yoursite.com/categories/ignite/"}],"tags":[{"name":"ignite","slug":"ignite","permalink":"http://yoursite.com/tags/ignite/"}]},{"title":"服务器OOM问题排查","slug":"服务器OOM问题排查","date":"2018-04-08T12:04:50.000Z","updated":"2018-06-29T11:42:08.781Z","comments":true,"path":"2018/04/08/服务器OOM问题排查/","link":"","permalink":"http://yoursite.com/2018/04/08/服务器OOM问题排查/","excerpt":"","text":"OOM最近碰上一起攻击，客户端的服务器被发送了N个500+M大小的空数据包，是从Ignite 的NIO通道传过来，导致客户端分配对应大小的堆内内存直接把应用程序挤爆了。记录一下当时分析OOM的过程。 命令查看进程gc情况，发现80s的时间有663次full gc，而且还在疯狂继续，忘截图了 - -12# 两秒打印一次进程gc情况jstat -gc pid 2000 保存dump文件12# 保存进程当前的dump文件jmap -dump:format=b,file=heap.fprof pid dump文件分析工具JProfile Start Center -&gt; Open Snapshots -&gt; Open a Single Snapshot 选中dump文件，打开后选择biggest Object，可以点击Instance Count根据对象大小排序 这里发现有6个542M大小的对象通过NIO通道被发送进来（ignite集群NIO通信）。 选择对象右键选择一个大对象，Use Select Instance，可以查看对象内部的具体内容，在meta中存放了这个大对象的内容。 在JProfile里打开可以看到数组存放的ASCII码，但是只有前面202个byte有数据，剩下的都是0。（怀疑遭到攻击） 当时的想法就是看一下ASCII码的具体内容，于是右键byte[]数组，选择export view，可以把数组内容导出到XML文件，写一个Java程序解析。 查看数据dump文件里最大的是char[]，JProfile不支持直接显示文本，可以先导出内容到XML文件(右键Export View选项)，然后用Java写一个解析XML文件的工具。1234567891011121314151617public class Test &#123; public static void main(String[] args) throws ParserConfigurationException, IOException, SAXException &#123; byte[] bytes = new byte[10010]; DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance(); DocumentBuilder db = dbf.newDocumentBuilder(); Document document = db.parse(\"Heap_walker_Outgoing_References.xml\"); NodeList list = document.getElementsByTagName(\"primitiveArrayData\"); for (int i = 0; i &lt; list.getLength(); i++) &#123; Node item = list.item(i); NamedNodeMap map = item.getAttributes(); Node node = map.getNamedItem(\"value\"); bytes[i] = Byte.valueOf(node.getNodeValue()); &#125; System.out.println(new String(bytes, \"UTF-8\")); &#125;&#125; 输出结果是:12345678http://www.rfa.org/ HTTP/1.1Host: www.rfa.orgConnection: keep-aliveAccept-Encoding: gzip, deflateAccept: */*User-Agent: python-requests/2.6.0 CPython/2.7.5 Linux/3.10.0-693.11.1.el7.x86_64... 省略一大波空行 解析其他几个大对象也是类似的内容 检查服务器从解析的内容上看基本可以肯定是被攻击了。回到服务器再次查看错误日志，发现rmtAddr很奇怪，用百度IP查询这个地址居然来自广东。理论上ignite的10800端口应该只用于集群间通信。 netstat查看服务器端口情况：1tcp 0 0 0.0.0.0:10800 0.0.0.0:* LISTEN 23116/java 嗯，完蛋。直接把端口暴露了，当时也没有给这个端口设置防火墙。 解决 设置ignite端口的防火墙，在阿里云ECS上配置安全组。线上稳定。 感想在发布当晚，应用上线后10分钟客户端OOM，以为是ignite配置出了问题，没有注意到这个异常IP，修改ignite参数后重启服务后正常。接着在隔天凌晨3店客户端再次OOM，同样的错误，系统一直gc。直到最后分析进程dump文件，发现端口被人利用发送了一堆垃圾数据导致应用服务器内存爆炸，意识到恶意攻击后才注意到这个异常IP，如果早点重视就不会出现被连续多次攻击的情况，还好及时封住了端口，没有造成严重后果。 捏一把汗。。 太 可 怕 了 ！！！","categories":[{"name":"ignite","slug":"ignite","permalink":"http://yoursite.com/categories/ignite/"},{"name":"工作总结","slug":"ignite/工作总结","permalink":"http://yoursite.com/categories/ignite/工作总结/"}],"tags":[{"name":"ignite","slug":"ignite","permalink":"http://yoursite.com/tags/ignite/"},{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"}]},{"title":"ignite运维-安全配置和主从复制","slug":"ignite运维-主从复制","date":"2018-02-28T06:16:11.000Z","updated":"2018-06-29T15:29:05.762Z","comments":true,"path":"2018/02/28/ignite运维-主从复制/","link":"","permalink":"http://yoursite.com/2018/02/28/ignite运维-主从复制/","excerpt":"","text":"环境操作系统：CentOS 7 ignite版本：2.3.0 节点：server x 2, client x 1 安装ignite安装和SpringData集成 集群安全ignite安全配置 生成证书文件会要求输入密码和一系列信息。1keytool -genkeypair -alias server -keyalg RSA -keystore server.jks XML配置12345678910&lt;bean id=\"cfg\" class=\"org.apache.ignite.configuration.IgniteConfiguration\"&gt; &lt;property name=\"sslContextFactory\"&gt; &lt;bean class=\"org.apache.ignite.ssl.SslContextFactory\"&gt; &lt;property name=\"keyStoreFilePath\" value=\"keystore/server.jks\"/&gt; &lt;property name=\"keyStorePassword\" value=\"123456\"/&gt; &lt;property name=\"trustStoreFilePath\" value=\"keystore/trust.jks\"/&gt; &lt;property name=\"trustStorePassword\" value=\"123456\"/&gt; &lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt; 在服务端和客户端节点上都要有相同的server.jks文件，启动时集群在ignite配置中通过jks文件和密码进行通信认证。 主从复制在Client端，SpringData要求配置IgniteCache，只要配置cacheMod为REPLICATED，即为主从复制。12345678910111213&lt;bean id=\"paperCache\" class=\"org.apache.ignite.configuration.CacheConfiguration\"&gt; &lt;!-- 数据网格名称，Repository注解使用 --&gt; &lt;property name=\"name\" value=\"PaperCache\"/&gt; &lt;!-- 缓存模式可以是PARTITIONED(分片)REPLICATED(主从复制)等 --&gt; &lt;property name=\"cacheMode\" value=\"REPLICATED\"/&gt; &lt;!-- 使用Ignite数据网格必须设置indexedTypes --&gt; &lt;property name=\"indexedTypes\"&gt; &lt;list&gt; &lt;value&gt;java.lang.Long&lt;/value&gt; &lt;value&gt;com.xhtc.ignite.vo.PaperVO&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;","categories":[{"name":"ignite","slug":"ignite","permalink":"http://yoursite.com/categories/ignite/"}],"tags":[{"name":"ignite","slug":"ignite","permalink":"http://yoursite.com/tags/ignite/"}]},{"title":"ignite安装和SpringData集成","slug":"ignite安装和SpringData集成","date":"2018-01-15T01:57:01.000Z","updated":"2018-06-29T11:42:08.782Z","comments":true,"path":"2018/01/15/ignite安装和SpringData集成/","link":"","permalink":"http://yoursite.com/2018/01/15/ignite安装和SpringData集成/","excerpt":"","text":"文章源码-c1_igniteStart Ignite安装使用版本：v_2.3.0 环境：一个server节点(Linux/Windows, IP:S.S.S.S), 一个client节点(IP:C.C.C.C) 目标：client节点集成SpringData，把数据网格存储到server内存。 下载安装包官网下载地址 apache-ignite-fabric-2.3.0-bin.zip 服务端节点直接wget安装包到服务器，unzip解压后进入bin目录，直接输入启动命令就能运行ignite，如果不指定配置文件，程序默认使用conf/default-config.xml $: ./ignite.sh 启动后就可以看到这个界面，这样一个ignite服务节点就算起好了（windows用ignite.bat启动） 客户端节点在maven应用中，添加ignite依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;properties&gt; &lt;ignite.version&gt;2.3.0&lt;/ignite.version&gt; &lt;spring.version&gt;4.3.14.RELEASE&lt;/spring.version&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;lombok.version&gt;1.16.20&lt;/lombok.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.ignite&lt;/groupId&gt; &lt;artifactId&gt;ignite-spring&lt;/artifactId&gt; &lt;version&gt;$&#123;ignite.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.ignite&lt;/groupId&gt; &lt;artifactId&gt;ignite-core&lt;/artifactId&gt; &lt;version&gt;$&#123;ignite.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.ignite&lt;/groupId&gt; &lt;artifactId&gt;ignite-spring-data&lt;/artifactId&gt; &lt;version&gt;$&#123;ignite.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.ignite&lt;/groupId&gt; &lt;artifactId&gt;ignite-log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;ignite.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.ignite&lt;/groupId&gt; &lt;artifactId&gt;ignite-indexing&lt;/artifactId&gt; &lt;version&gt;$&#123;ignite.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt;version&gt;1.4.196&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 写一个VO 用@QuerySqlField注解声明为数据网格字段，用index声明索引字段。12345678910111213141516//lombok注解，自动生成getter()和setter()@Datapublic class PaperVO &#123; @QuerySqlField(index = true) private Long paperId; @QuerySqlField private String title; @QuerySqlField private String author; @QuerySqlField private String school; @QuerySqlField private Date publicTime; ... builder代码&#125; 配置一个Client Bean1234567891011121314151617181920212223242526@Configuration//扫描basePackages包下的类，让这些类能够被注解为SpringData的仓库接口@EnableIgniteRepositories(basePackages = &#123;\"com.xhtc.ignite.repository\"&#125;)public class IgniteClient &#123; private IgniteConfiguration igniteConfiguration; public static Ignite ignite; public IgniteConfiguration getIgniteConfiguration() &#123; return igniteConfiguration; &#125; public void setIgniteConfiguration(IgniteConfiguration igniteConfiguration) &#123; this.igniteConfiguration = igniteConfiguration; &#125; //IgniteRepositoryBeanFactory指定要名为igniteInstance的Bean,可查看源代码 @Bean public Ignite igniteInstance() &#123; ignite = Ignition.start(igniteConfiguration); return ignite; &#125; public void destroy() &#123; //ignite的destroy方法必须传入数据网格名称作为参数 List&lt;String&gt; caches = new ArrayList&lt;&gt;(); caches.add(\"PaperCache\"); ignite.destroyCaches(caches); ignite.close(); &#125;&#125; XML配置具体的IgniteConfigurationignite具体的IgniteConfiguration配置写在xml文件中。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 扫描Repository包 --&gt; &lt;context:component-scan base-package=\"com.xhtc.ignite\"/&gt; &lt;bean id=\"igniteClient\" class=\"com.xhtc.ignite.IgniteClient\"&gt; &lt;property name=\"igniteConfiguration\" ref=\"igniteConfig\"/&gt; &lt;/bean&gt; &lt;bean id=\"igniteConfig\" class=\"org.apache.ignite.configuration.IgniteConfiguration\"&gt; &lt;!-- 配置为客户端节点(必须，否则默认为server) --&gt; &lt;property name=\"clientMode\" value=\"true\"/&gt; &lt;!-- 配置客户端节点名称 --&gt; &lt;property name=\"igniteInstanceName\" value=\"igniteStart\"/&gt; &lt;!-- 客户端关闭metrics日志打印(value类型long 设置60*1000L即为1分钟刷新一次metrics日志，设置为0即关闭) --&gt; &lt;!--&lt;property name=\"metricsLogFrequency\" value=\"0\"/&gt;--&gt; &lt;!-- server重启时客户端自动重连(value时间内服务端若重启客户端会自动重连)--&gt; &lt;property name=\"networkTimeout\" value=\"1000000\"/&gt; &lt;!-- 配置内存数据网格 --&gt; &lt;property name=\"cacheConfiguration\"&gt; &lt;list&gt; &lt;ref bean=\"paperCache\"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 配置集群ip(静态) --&gt; &lt;property name=\"discoverySpi\" ref=\"discoverySpi\"/&gt; &lt;/bean&gt; &lt;bean id=\"paperCache\" class=\"org.apache.ignite.configuration.CacheConfiguration\"&gt; &lt;!-- 数据网格名称，Repository注解使用 --&gt; &lt;property name=\"name\" value=\"PaperCache\"/&gt; &lt;!-- 缓存模式可以是PARTITIONED(分片)REPLICATED(主从复制)等 --&gt; &lt;property name=\"cacheMode\" value=\"PARTITIONED\"/&gt; &lt;!-- 使用Ignite数据网格必须设置indexedTypes --&gt; &lt;property name=\"indexedTypes\"&gt; &lt;list&gt; &lt;value&gt;java.lang.Long&lt;/value&gt; &lt;value&gt;com.xhtc.ignite.vo.PaperVO&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"discoverySpi\" class=\"org.apache.ignite.spi.discovery.tcp.TcpDiscoverySpi\"&gt; &lt;property name=\"ipFinder\"&gt; &lt;bean class=\"org.apache.ignite.spi.discovery.tcp.ipfinder.vm.TcpDiscoveryVmIpFinder\"&gt; &lt;property name=\"addresses\"&gt; &lt;list&gt; &lt;value&gt;S:S:S:S:47500..47509&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 业务逻辑用IgniteRepository实现数据存取到这里为止，Ignite客户端的环境和数据网格都已经配置好了，接下来就是业务逻辑。让业务逻辑接口继承IgniteRepository后，可以发现在写方法的时候智能提示Ignite的特定语法，类似这样： 关键词有”By”,”And”,”Between”,”OrderBy”等等，Ignite底层的SQL引擎会解析这些关键词，把接口名称转换为对应SQL语句，然后查询数据网格~ 高级(可以看下IgniteQueryGenerator.java这个类的方法)。除了接口方法特定的关键词，也可以用@Query注解自定义SQL进行操作，Ignite的SQL是符合ANSI SQL99规范的，可以参见官方文档 Ignite SQL。 所以这里，我的业务逻辑接口就写成下面这样。 123456789101112131415161718//cacheName指定数据网格@RepositoryConfig(cacheName = \"PaperCache\")public interface PaperRepository extends IgniteRepository&lt;PaperVO, Long&gt; &#123; /** * 获取指定作者的所有论文 */ List&lt;PaperVO&gt; getByAuthor(String author); /** * 获取作者的所有论文并以发布时间升序排列 */ List&lt;PaperVO&gt; getByAuthorOrderByPublicTimeAsc(String author); /** * 自定义SQL * 根据标题获取Paper */ @Query(\"SELECT * FROM PaperVO WHERE title = ?\") PaperVO getPaperBySQL(String title);&#125; 单元测试在执行单元测试时先启动Ignite，然后把需要的数据放入Ignite。四个@Test对IgniteRepository的方法进行测试。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;\"classpath:applicationContext-ignite.xml\"&#125;)public class IgniteStartTest &#123; @Autowired private IgniteClient igniteClient; @Autowired private PaperRepository paperRepository; private SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); @Before public void setUp() throws Exception &#123; //启动ignite igniteClient.igniteInstance(); //向paperCache存入数据 PaperVO x_paper1 = PaperVO.PaperVOBuilder.aPaperVO().paperId(1L).author(\"xhtc\").title(\"x_paper1\") .school(\"hdu\").publicTime(sdf.parse(\"2015-3-1 15:30:30\")).build(); PaperVO x_paper2 = PaperVO.PaperVOBuilder.aPaperVO().paperId(2L).author(\"xhtc\").title(\"x_paper2\") .school(\"hdu\").publicTime(sdf.parse(\"2015-10-1 10:00:00\")).build(); PaperVO c_paper1 = PaperVO.PaperVOBuilder.aPaperVO().paperId(3L).author(\"cccc\").title(\"c_paper1\") .school(\"hdu\").publicTime(sdf.parse(\"2016-5-7 10:00:00\")).build(); PaperVO c_paper2 = PaperVO.PaperVOBuilder.aPaperVO().paperId(4L).author(\"cccc\").title(\"c_paper2\") .school(\"hdu\").publicTime(sdf.parse(\"2016-11-7 10:00:00\")).build(); PaperVO c_paper3 = PaperVO.PaperVOBuilder.aPaperVO().paperId(5L).author(\"cccc\").title(\"c_paper3\") .school(\"hdu\").publicTime(sdf.parse(\"2014-11-11 11:00:00\")).build(); Map&lt;Long, PaperVO&gt; map = new HashMap&lt;&gt;(); map.put(1L, x_paper1); map.put(2L, x_paper2); map.put(3L, c_paper1); map.put(4L, c_paper2); map.put(5L, c_paper3); paperRepository.save(map); &#125; @After public void tearDown() throws Exception &#123; igniteClient.destroy(); &#125; @Test public void getByAuthorTest() throws ParseException &#123; List&lt;PaperVO&gt; list = paperRepository.getByAuthor(\"xhtc\"); assert list.size() == 2; assert list.get(0).getAuthor().equals(\"xhtc\"); assert list.get(1).getAuthor().equals(\"xhtc\"); &#125; @Test public void getByAuthorOrderByPublicTimeAscTest() throws ParseException &#123; List&lt;PaperVO&gt; list = paperRepository.getByAuthorOrderByPublicTimeAsc(\"cccc\"); assert list.size() == 3; assert list.get(0).getPublicTime().equals(sdf.parse(\"2014-11-11 11:00:00\")); assert list.get(1).getPublicTime().equals(sdf.parse(\"2016-5-7 10:00:00\")); assert list.get(2).getPublicTime().equals(sdf.parse(\"2016-11-7 10:00:00\")); &#125; @Test public void updatePaperTest() &#123; PaperVO paper = paperRepository.findOne(1L); assert paper.getTitle().equals(\"x_paper1\"); paper.setTitle(\"update_Title\"); paperRepository.save(paper.getPaperId(), paper); PaperVO paper2 = paperRepository.findOne(1L); assert paper2.getTitle().equals(\"update_Title\"); &#125; @Test public void getPaperBySQLTest() &#123; PaperVO paper = paperRepository.getPaperBySQL(\"c_paper2\"); assert paper.getPaperId() == 4; &#125;&#125; IDEA运行单元测试时(打住断点)，在控制台可以看到节点数变化 要注意的点 PaperRepository继承了IgniteRepository，而IgniteRepository继承了CrudRepository，本质上就是IgniteRepositoryImpl(IgniteRepository的实现类)，用IgniteCache&lt;ID, T&gt; cache获取到内存数据网格，然后用Ignite自己的API封装了一套CRUD方法。要注意的是: 如果PaperVO自己的paperId为null, 用save(Long Id, Object o)方法保存到Ignite网格后，字段paperId依然为null，无法在接口方法中使用”SELECT * FROM PapaerVO Where paperId = ?“这条SQL查询。 Ignite自定义SQL（@Query）不支持UPDATE语法，如果要更新某条记录，直接取出VO修改后再重新save即可。 Ignite SpringData一个比较大的问题就是，当自定义SQL不能正确执行，只会报一个 “fail to parse SQL” 的错误，不会直接提醒哪错了。 如果不配置SpringData，可以根据caheName取出IgniteCache&lt;ID, T&gt; cache，直接用Ignite Api进行操作，可以参考文档，或者看下IgniteRepositoryImpl这个类就能了解大概了。 缺点，相比直接操作接口，这种方法比较麻烦。 优点，SpringData需要提前再XML里配置IndexedTypes，而Ignite Api可以 ignite.getOrCreate(String cacheName)。 SpringData中自带了jcl桥接依赖，会自动把log4j转成sfl4j，如果不想这么做，在maven中exclusion这个依赖即可。 踩坑补充 SpringData只支持SELECT方法，就是只能用来查询，如果需要修改，就调用save(KEY,VO)方法覆盖键值。 另外findOne(KEY)方法是CrudRepository的原生方法，默认取出一个迭代器(永远不会是null)，如果要从数据网格查询，就在SpringData接口里写一个findById(ID)的方法，如果数据不存在就会返回null。","categories":[{"name":"ignite","slug":"ignite","permalink":"http://yoursite.com/categories/ignite/"}],"tags":[{"name":"ignite","slug":"ignite","permalink":"http://yoursite.com/tags/ignite/"}]},{"title":"设计模式","slug":"设计模式","date":"2017-12-14T13:53:14.000Z","updated":"2018-06-29T11:42:08.781Z","comments":true,"path":"2017/12/14/设计模式/","link":"","permalink":"http://yoursite.com/2017/12/14/设计模式/","excerpt":"","text":"策略模式 概念：定义了算法族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化独立于使用算法的客户。 设计原则： 找出应用中可能需要变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起。 针对借口编程，而不是针对实现编程。 多用组合，少用继承。 理解：分离事物的实体和行为，用注入的方式给实体接入行为，用接口实现的方式创建各种可以相互替换的行为实体。 观察者模式 概念：在对象之间定义一对多的依赖，这样一来，当一个对象改变状态，依赖它的对象会收到通知，并自动更新。 +设计原则： 为交互对象之间的松耦合设计而努力。 Java中的运用： Swing(按钮注入监听)，JavaBean，RMI等。 理解： 有”推”和”拉”两种模式。 推是指主题维护一组观察者(列表)，发生变化时主动把数据推送给观察者。但是这样做逻辑比较死板，有的观察者可能并不需要这么多数据。 拉是指主题不主动推，观察者在需要的时候向主题主动拉取自己需要的数据。 装饰模式 概念：动态地将责任附加到对象上。若要扩展功能，装饰者提供了比继承更有弹性的替代方案。 装饰者和被装饰者对象有相同的超类型。 你可以用一个或多个装饰者包装一个对象。 既然装饰者和被装饰对象有相同的超类型，所以在任何需要原始对象（被包装）的场合，可以用装饰过的对象替代它。 装饰者可以在所委托被装饰者的行为之前与/或之后加上自己的行为，以达到特殊目的。 对象可以在任何时候被装饰，所以可以在运行时动态地、不限量地用你喜欢的装饰者来装饰对象。 +设计原则： 开放-关闭原则。类应该对扩展开放，对修改关闭。d Java中的应用： I/O组件。 工厂模式 概念：定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类把实例化推迟到子类。 +设计原则： 要依赖抽象，不要依赖具体类。 抽象工厂模式 概念：提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。 理解：定义一个创建产品家族的抽象类型，其实就是用抽象类处理共有部分，用子类实现抽象方法满足需求变化，用接口注入的方式达到“组合”和“解耦”的目的。（工厂方法用的是继承） 相比工厂方法的优点：除了能够将客户从具体类型中解耦，还能把一群相关的产品集合起来。 相比工厂方法的缺点：如果要扩展这组产品，就必须改变接口。 命令模式 概念：将“请求”封装成对象，以便使用不同的请求，队列或者日志来参数化其他对象，命令模式也支持可撤销的操作。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/categories/读书笔记/"}],"tags":[{"name":"HeadFirst设计模式","slug":"HeadFirst设计模式","permalink":"http://yoursite.com/tags/HeadFirst设计模式/"}]},{"title":"Java并发编程实战-读书笔记","slug":"Java并发编程实战-读书笔记","date":"2017-12-14T10:35:15.000Z","updated":"2018-06-29T11:42:08.787Z","comments":true,"path":"2017/12/14/Java并发编程实战-读书笔记/","link":"","permalink":"http://yoursite.com/2017/12/14/Java并发编程实战-读书笔记/","excerpt":"","text":"第二章P19程序清单2-5 该Servlet再没有足够原子性保证的情况下对其最近计算结果进行缓存(不要这么做)12 想起项目中的缓存处理，通常对数据库的数据进行读写时，都尽量把数据库操作和缓存操作都放在配置事务的Service类里，保证数据库和缓存的数据一致性。 第三章P30 加锁的含义不仅仅局限于互斥行为，还包括内存可见性。为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。 为什么访问某个共享且可变的变量时要求所有线程再同一个锁上同步？ 为了确保某个线程写入该变量的值对于其他线程来说都是可见的。 Volatile关键字(比synchronized更轻量级的同步机制) 编译器会注意到这个变量是共享的，不会讲该变量上的操作和其他内存操作一起重排序。 保证可见性，但不保证原子性。 通常用做某个操作完成、发生中断或者状态的标志。 使用原则 对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。 该变量不会与其他状态变量一起纳入不变性条件中。 访问变量时不需要加锁。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/categories/读书笔记/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"支付模块总结","slug":"支付模块总结","date":"2017-12-13T05:25:21.000Z","updated":"2018-06-29T11:42:08.783Z","comments":true,"path":"2017/12/13/支付模块总结/","link":"","permalink":"http://yoursite.com/2017/12/13/支付模块总结/","excerpt":"","text":"原创内容，转载请注明出处。 本文为个人学习和总结，有不正确的内容欢迎指出。 支付宝接口官方文档接入一下接口之前必须先开通对应服务，否则没有权限访问接口。审核大概需要一天，也可以联系支付宝客服加急处理。 接入当面付接口文档 手机网站支付接口文档 单笔转账接口文档 开放平台联调日志排查 支付流程方案在生活号里调用支付可以通过手机网站支付接口和统一收单交易创建接口+js这两种方式。两种方式区别如下(后台)： 前者返回form表单，前端发起支付请求后无法控制支付弹窗等，如果用户在弹窗上直接取消支付，就直接返回到支付宝首页，无法进行逻辑处理。后者调起支付弹窗前端可以catch到，并植入响应的逻辑处理，更加灵活。 前者无论是否支付成功都会发起异步通知（见’通知触发条件’）。后者只有支付成功才会发起异步通知。这个区别导致我一厢情愿地认为都是只有支付成功才会发起异步通知，没有在异步接收通知请求的接口里校验参数，直接进入到下一个业务逻辑，还好多瞄了一眼文档，及时发现。 支付宝配置 开发者中心 -&gt; 生活号 -&gt; 应用列表 -&gt; ‘选择应用’ -&gt; 应用信息 设置应用公钥，这里只要下载密钥生成器，保存好私钥，并且上传对应的公钥就可以，同一个应用的支付宝公钥固定不变。 设置授权回调地址，保证和授权接口的回调地址统一。 用生成的私钥和支付宝公钥，在后台实例化支付宝客户端，就可以调用支付宝接口了~。 1AlipayClient alipayClient = new DefaultAlipayClient(\"https://openapi.alipay.com/gateway.do\", APP_ID, APP_PRIVATE_KEY, \"json\", CHARSET, ALIPAY_PUBLIC_KEY, \"RSA2\"); 业务流程用户在发起支付时，后台先生成订单和预支付流水(务必在事务外先生成流水记录)，然后在Service层中发起同步调用和状态更新等业务操作。 原因 进行事务操作时需要更新这条交易流水记录，因此在发起事务时必须保证这条记录存在。 如果放在事务中创建流水，那么有可能支付宝异步回调通知服务端的时候，后台事务还没有提交，无法找到这条交易记录，导致Service第二个”更新订单和流水状态”的操作失败。 关于转账如果A是支付宝接口的调用者，支付宝并不支持A通过接口调用直接把B的钱打给C。因此如果是做平台的话，存在这种三方关系，只能通过单笔转账接口完成业务逻辑，先让B把钱打给A，再由A把钱转账给C，因此B付款后在订单里看到的收款方是A，C收到款项后在订单里看到的付款方也是A。 这里两步交易必须做好一系列校验 必须保证A已经收到B的款项再发起对C的转账。 如果转账(同步接口)没有成功，先调查询接口查询转账接口，确认为转账失败再重新发起请求，避免重复转账。 整个业务中可能出现2-3次对支付宝服务器的请求，为了避免超时，可以把部分业务拆分出来，由消息队列去发起请求。 转账业务里有的异常情况重试无效，比如找不到用户，或者实名认证不匹配，或者金额过低（转账0.1元起），这些情况可以直接发起报警。 坑 支付宝接口转账不需要手续费，但是收款需要手续费，普通费率是0.06%。","categories":[{"name":"工作总结","slug":"工作总结","permalink":"http://yoursite.com/categories/工作总结/"}],"tags":[{"name":"Work","slug":"Work","permalink":"http://yoursite.com/tags/Work/"}]},{"title":"方法参数的有效性检查","slug":"方法参数的有效性检查","date":"2017-11-30T13:22:08.000Z","updated":"2018-06-29T11:42:08.784Z","comments":true,"path":"2017/11/30/方法参数的有效性检查/","link":"","permalink":"http://yoursite.com/2017/11/30/方法参数的有效性检查/","excerpt":"","text":"原创内容，转载请注明出处。 本文为个人学习和总结，有不正确的内容欢迎指出。 关注点及参考 Bean Validation, JSR303,349 http://beanvalidation.org/ http://blog.csdn.net/xlgen157387/article/details/46848507 参数校验最近版本测试的bug单里发现空指针的异常占比有点大，最头疼的报错就是”服务器错误”，告诉你后台错了，又没告诉你后台哪错了，尽管我已经尽可能在关键点打出日志，但是空指针的问题还是会经常出现。 总结下来主要是这几种情况: 方法入参的校验。（这种校验相对比较容易） 调用他人接口返回值没有校验直接使用。（对接赢商通，在比较请求流水的时候，有些错误返回没有流水，直接拿来比较抛了空指针） 组装参数后没有校验，调用他人接口被返回空指针异常。(除非接口会明确返回缺少的参数) 有些跨越方法被传递的引用参数，没有进行校验。 构造器的参数校验。(Effective Java, Item 38 补充) 代码 环境 JDK1.7 pom依赖 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;javax.el&lt;/groupId&gt; &lt;artifactId&gt;javax.el-api&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.glassfish.web&lt;/groupId&gt; &lt;artifactId&gt;javax.el&lt;/artifactId&gt; &lt;version&gt;2.2.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;5.4.1.Final&lt;/version&gt;&lt;/dependency&gt; 示例1（针对第1种情况） 一般我都会在自己写的方法前两行，打印日志后接上参数校验的操作，校验到缺少参数直接抛给调用者。尤其是入参包含的域比较多的时候，这种校验会很有效。 除了示例1的@NotNull，Bean Validation还提供其他校验，具体可以参见JavaDoc。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ValidatorClass &#123;private static Validator validator = Validation.buildDefaultValidatorFactory().getValidator();private static class Person &#123; @Getter @Setter @NotNull(message = \"name不可为空\") private String name;&#125;static void check(Object object) &#123; Set&lt;ConstraintViolation&lt;Object&gt;&gt; violations = validator.validate(object); Iterator&lt;ConstraintViolation&lt;Object&gt;&gt; iterator = violations.iterator(); if (iterator.hasNext()) &#123; String errMessage = iterator.next().getMessage(); System.out.println(errMessage); throw new ValidationException(errMessage); &#125;&#125;private static void test1() &#123; //实例化对象但不设置name Person person = new Person(); try &#123; check(person); &#125; catch (ValidationException e) &#123; //输出“name不可为空” System.out.println(e.getMessage()); return; &#125; System.out.println(\"test1 passed\");&#125;private static void test2() &#123; //实例化对象且设置name Person person = new Person(); person.setName(\"xhtc\"); try &#123; check(person); &#125; catch (ValidationException e) &#123; System.out.println(e.getMessage()); return; &#125; System.out.println(\"test2 passed\");&#125;public static void main(String[] args) &#123; test1(); test2();&#125; 示例2。（针对第2种，会出现两种情况，一是我自己写接收参数，我当然可以在自己的类里定义校验，并且在接收到参数后马上进行结果校验，但是往往对于接口返回结果的处理不是单一的，需要校验的参数也不一样。二是在三方包自带出参类，这样就无法在类里添加自定义注解进行校验。） 如果是对于同一个类存在多种校验，可以使用group参数对校验进行分类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class ValidatorClass4Group &#123;private static Validator validator = Validation.buildDefaultValidatorFactory().getValidator();private static class Person &#123; @Getter @Setter @NotNull(message = \"name不可为空\", groups = &#123;INFO.class, STUDENT.class, EMPLOYEE.class&#125;) private String name; @Getter @Setter @NotNull(message = \"studentId不可为空\", groups = &#123;INFO.class, STUDENT.class&#125;) private Integer studentId; @Getter @Setter @NotNull(message = \"employId不可为空\", groups = &#123;INFO.class, EMPLOYEE.class&#125;) private Integer employId;&#125;private static void check(Object object, Class&lt;?&gt;... groups) &#123; Set&lt;ConstraintViolation&lt;Object&gt;&gt; violations = validator.validate(object, groups); Iterator&lt;ConstraintViolation&lt;Object&gt;&gt; iterator = violations.iterator(); if (iterator.hasNext()) &#123; String errMessage = iterator.next().getMessage(); throw new ValidationException(errMessage); &#125;&#125;private static void test1() &#123; Person intern = new Person(); intern.setName(\"xhtc\"); intern.setStudentId(1); intern.setEmployId(1); try &#123; check(intern, INFO.class); &#125; catch (ValidationException e) &#123; System.out.println(e.getMessage()); return; &#125; System.out.println(\"test1 passed\");&#125;private static void test2() &#123; Person student = new Person(); student.setName(\"xhtc\"); student.setStudentId(1); try &#123; check(student, STUDENT.class); &#125; catch (ValidationException e) &#123; System.out.println(e.getMessage()); return; &#125; System.out.println(\"test2 passed\");&#125;private static void test3() &#123; Person employee = new Person(); employee.setName(\"xhtc\"); employee.setEmployId(1); try &#123; check(employee, EMPLOYEE.class); &#125; catch (ValidationException e) &#123; System.out.println(e.getMessage()); return; &#125; System.out.println(\"test3 passed\");&#125;public static void main(String[] args) &#123; test1(); test2(); test3();&#125;interface STUDENT &#123;&#125;;interface EMPLOYEE &#123;&#125;;interface INFO &#123;&#125;;&#125; 如果是三方包自带了返回参数的类，那么在使用域的时候一定要先进行有效性判断再使用。包括： != null StringUtils.isNotEmpty() CollectionUtils.isNotEmpty() 其他等等 第3种情况，我只想说开发的时候一定要养成好习惯，不管是别人调用自己的方法还是自己调用别人的方法，都要保证自己的代码足够严谨，如果别人的接口返回了有效性校验，这当然是非常好的，如果他没有，那么就必须保证自己传出的参数是正确的，这个情况同样可以用以上方法解决。问题在于程序员的惰性~，有时候写多了就不愿意去做这些校验了。 第4种情况，这种跨越方法传递同一个对象引用的情况往往发生在一个类拥有大量的域，它们又没有被适当地封装，只能在不同业务场景下传递引用来填塞对象的内容，虽然我的直觉告诉我这样做不好，但是项目里有很多这样的代码，如果非要进行参数检查或者分类参数检查，我更确信做好业务分类和封装能更好地解决这个问题。 第5种情况，这是Effective Java第38条提到的内容。目前在项目中直接用注解进行参数校验的写法比较多，但是在参数比较少，或者构造器参数比较少（4个参数或者更少）的情况下，直接在构造方法里进行参数校验会比注解校验效率更高，封装性也会更好，以后可以尝试这种做法。","categories":[{"name":"工作总结","slug":"工作总结","permalink":"http://yoursite.com/categories/工作总结/"}],"tags":[{"name":"Work","slug":"Work","permalink":"http://yoursite.com/tags/Work/"},{"name":"Effective Java","slug":"Effective-Java","permalink":"http://yoursite.com/tags/Effective-Java/"}]},{"title":"Java注解 学习总结","slug":"Java注解-学习总结","date":"2017-08-14T05:41:49.000Z","updated":"2018-06-29T11:42:08.785Z","comments":true,"path":"2017/08/14/Java注解-学习总结/","link":"","permalink":"http://yoursite.com/2017/08/14/Java注解-学习总结/","excerpt":"","text":"注解可以理解为是一套必须带有默认值的接口方法，相比接口，注解在代码中更像是一种描述或者标记。Java里有三种标准注解：@Override – 标记为覆盖超类方法。@Deprecated – 标记为过期。@SuppressWarnings – 标记为不提示编译警告。 四种元注解（负责注解其他注解）：@Target – 标记注解使用范围。（FIELD-域，METHOD-方法，TYPE-类型，CONSTRUCTOR-构造器，等等）@Retention – 标记为保存该注解信息的级别。（RUNTIME-VM在运行期也保留注解，因此可以通过反射机制读取注解信息，SOURCE-注解会被编译器丢弃，CLASS-注解正在class文件中可用，但会被VM丢弃）@Documented –标记此注解包含在Javadoc中。@Inherited – 允许子类继承父类中的注解。 模拟数据库字段约束示例所有注解的RetentionPolicy都是RUNTIME，这样才可以在注解处理器中用反射获取注解信息。 1234567//Target约束注解为TYPE，注解用于‘类’//注解数据库表，name()为表名@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface DBTable &#123; String name() default \"\";&#125; 123456789//Target约束注解为FIELD，注解用于‘域’//此注解为约束，设置字段是否主键，是否允许为空，是否为唯一索引等@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface Constraints &#123; boolean primaryKey() default false; boolean allowNull() default true; boolean unique() default false;&#125; 12345678//整数字段类型的注解，表示某个域为整型//同时嵌套了Constraints约束注解@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface SQLInteger &#123; String name() default \"\"; Constraints constraints() default @Constraints;&#125; 12345678910//同SQLInteger注解，这是一个VARCHAR类型的域注解//length为设定长度@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface SQLString &#123; //字段长度 int length() default 0; String name() default \"\"; Constraints constrants() default @Constraints;&#125; 123456789101112//Decimal类型@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface SQLDecimal &#123; //字段名称 String name() default \"\"; //长度为10 int length() default 10; //精度为2 int precision() default 2; Constraints constraints() default @Constraints;&#125; 创建一张表，用注解描述表名和字段类型12345678910111213141516171819202122//表名为MemberName@DBTable(name = \"MemberName\")public class Member &#123; //默认赋值到int @SQLString(length = 30) private String firstName; @SQLString(length = 50) private String lastName; @SQLInteger private Integer age; @SQLString(length = 30, constrants = @Constraints(primaryKey = true)) private String handle; @SQLDecimal private BigDecimal salary; getters() and setters ..&#125; 读取创建信息的注解处理器（反射）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class TableCreator &#123; public static void main(String[] args) throws ClassNotFoundException &#123; String[] tables = new String[]&#123;\"chapter20_annotation.generatingExternalFiles.Member\"&#125;; for (String className : tables ) &#123; //反射得到类型信息 Class&lt;?&gt; cl = Class.forName(className); //获取类上指定的注解 DBTable dbTable = cl.getAnnotation(DBTable.class); //如果参数列表的类中不存在DBTable注解，跳过 if (dbTable == null) &#123; System.out.println(\"No Table annotation in class \" + className); continue; &#125; String tableName = dbTable.name(); if (tableName.length() &lt; 1) &#123; tableName = cl.getName().toUpperCase(); &#125; //类型注解名称 System.out.println(\"tableName: \" + tableName); List&lt;String&gt; columnDefs = new ArrayList&lt;&gt;(); //获取类中的成员 for (Field field : cl.getDeclaredFields()) &#123; //字段名称 String columnName = null; //获取成员上的注解列表 Annotation[] anns = field.getDeclaredAnnotations(); if (anns.length &lt; 1) continue; //数据库表中每个字段只会有一种数据类型，数据类型注解中嵌套了约束注解，所以只需用anns[0] if (anns[0] instanceof SQLInteger) &#123; SQLInteger sInt = (SQLInteger) anns[0]; if (sInt.name().length() &lt; 1) &#123; columnName = field.getName().toUpperCase(); &#125; else &#123; columnName = sInt.name(); &#125; columnDefs.add(columnName + \" INT\" + getConstraints(sInt.constraints())); &#125; if (anns[0] instanceof SQLString) &#123; SQLString sString = (SQLString) anns[0]; if (sString.name().length() &lt; 1) &#123; columnName = field.getName().toUpperCase(); &#125; else &#123; columnName = sString.name(); &#125; columnDefs.add(columnName + \" VARCHAR(\" + sString.length() + \")\" + getConstraints(sString.constrants())); &#125; if (anns[0] instanceof SQLDecimal) &#123; SQLDecimal sDecimal = (SQLDecimal) anns[0]; if (sDecimal.name().length() &lt; 1) &#123; columnName = field.getName().toUpperCase(); &#125; else &#123; columnName = sDecimal.name(); &#125; columnDefs.add(columnName + \" Decimal(\" + sDecimal.length() + \", \" + sDecimal.precision() + \")\" + getConstraints(sDecimal.constraints())); &#125; &#125; StringBuilder createCommand = new StringBuilder(\"CREATE TABLE \" + tableName + \"(\"); for (String columnDef : columnDefs) createCommand.append(\"\\n \").append(columnDef).append(\".\"); String tableCreate = createCommand.substring(0, createCommand.length() - 1) + \");\"; System.out.println(\"Table Creation SQL for \" + className + \" is :\\n\" + tableCreate); &#125; &#125; 123456789打印结果tableName: MemberNameTable Creation SQL for chapter20_annotation.generatingExternalFiles.Member is :CREATE TABLE MemberName( FIRSTNAME VARCHAR(30). LASTNAME VARCHAR(50). AGE INT. HANDLE VARCHAR(30) PRIMARY KEY. SALARY Decimal(10, 2)); 注解处理器解析出代码中的注解，并根据数据库语法规则打印出创建MemberName表的SQL语句。以上自定义注解的RetentionPolicy.RUNTIME设定，可以在运行时期通过Java反射机制获取注解在内存模型中的信息。下面的图是我根据自己的理解画的，比较简单。 Java通过反射进入内存模型中的方法区，方法区里包含类型信息，getAnnotation()方法可以获得类上指定的注解，示例中是检查了DBTable注解是否存在在这个类中，获取DBTable注解后通过 dbTable.name()就获取到设定的表名（注解可以理解成是带有默认值的接口，所以这个操作就是获取了方法的返回值）。同样在域值上，field.getDeclaredAnnotations()方法可以获取某个域上的注解列表，然后遍历注解列表逐个解析。理解了内存模型，这一点就不难了。 RemarkSpring里有很多在类型上的注解，比如@Service，@Controller，等都可以自定义一个类名，当然在真实框架中不可能用这么暴力的注解处理器，每次都去做全局的遍历，《Thinking In Java》中提到了观察者模式下的注解处理器，还没怎么看明白，先在此记录一下注解本身的原理和用法吧~ 再接再厉~","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://yoursite.com/categories/读书笔记/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"}]},{"title":"SpringBoot初步实践","slug":"SpringBoot-start","date":"2017-06-16T06:53:55.000Z","updated":"2018-06-29T11:42:08.786Z","comments":true,"path":"2017/06/16/SpringBoot-start/","link":"","permalink":"http://yoursite.com/2017/06/16/SpringBoot-start/","excerpt":"","text":"准备maven配置新建一个maven项目，不用多说，配置pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;!-- 直接继承父类，记得添加最后的repository标签的内容--&gt; &lt;!-- 也可以自己指定SpringBoot依赖包的版本号 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springboot&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 一个很好用的注解插件，需要在IDEA-Setting-Plugin中安装lombok插件才能用 --&gt; &lt;!-- 也可以不加入这个依赖包，用传统方式生成getter和setter --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.16&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- mysql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- spring boot --&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- spring boot --&gt; &lt;!-- Add Spring repositories --&gt; &lt;!-- (you don't need this if you are using a .RELEASE version) --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;url&gt;http://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;url&gt;http://repo.spring.io/milestone&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;url&gt;http://repo.spring.io/snapshot&lt;/url&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;url&gt;http://repo.spring.io/milestone&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; 数据库配置插两张表和一条记录1234567891011121314151617CREATE TABLE IF NOT EXISTS t_user( user_id INT AUTO_INCREMENT PRIMARY KEY, user_name VARCHAR(30), credits INT, password VARCHAR(32), last_visit datetime, last_ip VARCHAR(23))ENGINE=InnoDB;CREATE TABLE t_login_log( login_log_id INT AUTO_INCREMENT PRIMARY KEY, user_id INT, ip VARCHAR(23), login_datetime datetime)ENGINE=InnoDB;INSERT INTO t_user(user_name, password)VALUES('admin','123456'); 然后在项目中添加application.properties文件，配置数据库信息。1234567891011121314151617spring.datasource.url=jdbc:mysql://localhost:3306/webstudyspring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.max-wait=10000spring.datasource.max-active=50spring.datasource.max-idle=10spring.datasource.min-idle=8spring.datasource.test-on-borrow=truespring.datasource.validation-query=select 1# 指定视图路径的前缀spring.mvc.view.prefix=/WEB-INF/jsp/# 指定视图文件的后缀spring.mvc.view.suffix=.jsp 项目文件结构dao层：负责直接和数据库中的数据打交道。domain：VO或SO，主要是出参入参的数据结构类。service：业务逻辑层，带事务的逻辑一般都放在这层。controller：web页面跳转控制。 右击项目名称-&gt;Add Framework Support -&gt; 添加Web Application模块。 要注意的是：IDEA自动添加的web模块位置需要调整一下，不然会报找不到jps文件的错误。web目录结构如下。 代码此案例用最基本的JDBC和数据库交互，习惯性先写domain层，简单暴力。（如果用mybatis可以自动生成mapping文件） domain层User.java123456789101112131415161718public class User implements Serializable &#123; //lombok注解工具，也可以直接使用传统的方法生成getter和setter @Getter @Setter private int userId; @Getter @Setter private String userName; @Getter @Setter private int credits; @Getter @Setter private String lastIp; @Getter @Setter private Date lastVisit;&#125; LoginLog.java1234567891011121314public class LoginLog implements Serializable &#123; @Getter @Setter private int loginLogId; @Getter @Setter private int userId; @Getter @Setter private String ip; @Getter @Setter private Date loginDate;&#125; LoginCommand.java123456789//登录使用的入参，后面会用到public class LoginCommand &#123; @Getter @Setter private String userName; @Getter @Setter private String password;&#125; dao层UserDao.java123456789101112131415161718192021222324252627282930313233343536@Repositorypublic class UserDao &#123; @Autowired private JdbcTemplate jdbcTemplate; private final static String MATCH_COUNT_SQL = \"SELECT count(*) FROM t_user WHERE user_name=? AND password=?\"; private final static String UPDATE_LOGIN_INFO_SQL = \"UPDATE t_user SET last_visit=?, last_ip=?, credits=?, WHERE user_id=?\"; //查询数据库中是否存在相应用户 public int getMatchCount(String userName, String password)&#123; return jdbcTemplate.queryForObject(MATCH_COUNT_SQL, new Object[] &#123;userName, password&#125;, Integer.class); &#125; //根据用户名查询用户信息 public User findUserByUserName(final String userName)&#123; final User user = new User(); jdbcTemplate.query(MATCH_COUNT_SQL, new Object[]&#123;userName&#125;, new RowCallbackHandler() &#123; public void processRow(ResultSet resultSet) throws SQLException &#123; user.setUserId(resultSet.getInt(\"user_id\")); user.setUserName(userName); user.setCredits(resultSet.getInt(\"credits\")); &#125; &#125;); return user; &#125; //用户登录后，更新数据库信息，修改用户最后访问时间和登录ip，增加用户积分 public void updateLoginInfo(User user)&#123; jdbcTemplate.update(UPDATE_LOGIN_INFO_SQL, user.getLastVisit(), user.getLastIp(), user.getCredits(), user.getUserId()); &#125;&#125; LoginDao.java123456789101112131415@Repositorypublic class LoginLogDao &#123; @Autowired private JdbcTemplate jdbcTemplate; private final static String INSERT_LOGIN_LOG_SQL= \"INSERT INTO t_login_log(user_id, ip, login_dateteme)VALUES(?,?,?)\"; //在数据库中插入用户登录的日志信息 public void insertLoginLog(LoginLog loginLog)&#123; Object[] args = &#123;loginLog.getUserId(), loginLog.getIp(), loginLog.getLoginDate()&#125;; jdbcTemplate.update(INSERT_LOGIN_LOG_SQL, args); &#125;&#125; service层1234567891011121314151617181920212223242526272829303132333435@Servicepublic class UserService &#123; @Autowired private UserDao userDao; @Autowired private LoginLogDao loginLogDao; public boolean hasMatchUser(String userName, String password)&#123; int matchCount = userDao.getMatchCount(userName, password); return matchCount &gt; 0; &#125; public User findUserByUserName(String userName)&#123; return userDao.findUserByUserName(userName); &#125; /** * 事务增强 * @param user */ @Transactional public void loginSuccess(User user)&#123; user.setCredits(5 + user.getCredits()); LoginLog loginLog = new LoginLog(); loginLog.setUserId(user.getUserId()); loginLog.setIp(user.getLastIp()); loginLog.setLoginDate(user.getLastVisit()); //方法做了事务增强，此处同时修改用户表和登录日志表，如果在过程中出错或者中断， //数据库内容自动就会回滚到没有执行这个方法的状态。 userDao.updateLoginInfo(user); loginLogDao.insertLoginLog(loginLog); &#125;&#125; Controller层12345678910111213141516171819202122232425262728@Controllerpublic class LoginController &#123; @Autowired private UserService userService; //可以配置多个映射路径 @RequestMapping(value = &#123;\"/\", \"/index.html\"&#125;, method = RequestMethod.GET) public ModelAndView loginPage()&#123; return new ModelAndView(\"login\"); &#125; @RequestMapping(value = \"/loginCheck.html\", method = RequestMethod.GET) public ModelAndView loginCheck(HttpServletRequest request, LoginCommand loginCommand)&#123; boolean isValidUser = userService.hasMatchUser(loginCommand.getUserName(), loginCommand.getPassword()); if(!isValidUser)&#123; return new ModelAndView(\"login\", \"error\",\"用户名密码错误\"); &#125; else &#123; User user = userService.findUserByUserName(loginCommand.getUserName()); user.setLastIp(request.getLocalAddr()); user.setLastVisit(new Date()); userService.loginSuccess(user); request.getSession().setAttribute(\"user\", user); return new ModelAndView(\"main\"); &#125; &#125; jsp代码login.jsp123456789101112131415161718192021&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;xhtc&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;c:if test=\"$&#123;!empty error&#125;\"&gt;&lt;font color=\"red\"&gt;&lt;c: out value=\"$&#123;error&#125;\"/&gt;&lt;/font&gt;&lt;/c:if&gt;&lt;form action='&lt;c:url value=\"/loginCheck.html\"/&gt;' method=\"post\"&gt; 用户名: &lt;input type=\"text\" name=\"userName\"&gt; &lt;br&gt; 密码: &lt;input type=\"password\" name=\"password\"&gt; &lt;br&gt; &lt;input type=\"submit\" value=\"登录\"/&gt; &lt;input type=\"reset\" value=\"重置\"/&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 此时的工程目录结构。 启动SpringBootapplication.java123456789101112131415161718192021222324@SpringBootApplication//开启事务支持，可以在Service方法上标注@Transaction表示事务增强@EnableTransactionManagementpublic class Application extends SpringBootServletInitializer&#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; protected SpringApplicationBuilder configure(SpringApplicationBuilder application)&#123; return application.sources(Application.class); &#125; /** * 自定义事务管理方法 * 此时SpringBoot会加载自定义的事务管理器，不会重新实例化其他事务管理器 * @param dataSource * @return */ @Bean public PlatformTransactionManager txManager(DataSource dataSource)&#123; return new DataSourceTransactionManager(dataSource); &#125;&#125; “基于Spring Boot应用，由于当前应用包含了一个可直接执行的Application类，所以在开发过程中，大家很容易在IDE（如IDEA工具）中单击右键鼠标运行当前类。虽然可以启动当前应用，在非Web应用中可能不会有什么问题，单在Web应用中，如果采用上述方法直接运行应用，那么在访问有视图的页面时（如JSP），会一直报404错误。因为直接运行当前启动类，Spring Boot无法找到当前页面资源。因此，基于Spring Boot的应用在开发调试的时候，一定要基于Spring Boot提供的spring-boot-maven-plugin插件命令来运行应用或通过Spring Boot命令行来运行应用。” —— 摘自&lt;精通Spring 4.x ——企业应用开发实战&gt; 所以，在web应用中，要用这样的方法去启动SpringBoot。 启动成功后，在浏览器输入 http://localhost:8080/ 即可看到登录页面。 部署成功！","categories":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/categories/JavaWeb/"}],"tags":[{"name":"Web","slug":"Web","permalink":"http://yoursite.com/tags/Web/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://yoursite.com/tags/SpringBoot/"}]},{"title":"mybatis generator 自动生成代码工具","slug":"mybatisGenerator","date":"2017-06-14T02:23:25.000Z","updated":"2018-06-29T11:42:08.783Z","comments":true,"path":"2017/06/14/mybatisGenerator/","link":"","permalink":"http://yoursite.com/2017/06/14/mybatisGenerator/","excerpt":"","text":"准备：IDEA安装mybatis plugin插件。 然后替换一下目录中的batis插件的jar包（多金的可以直接付费使用，支持正版）。&lt;img src=”http://oq6lqcu6w.bkt.clouddn.com/mgenerator_2_replace_mybatis_plus_jars.png&quot;width=&quot;70%&quot; height=”50%”&gt; 破解jar包分享地址：http://pan.baidu.com/s/1jHDDSqE 密码：7gdc 数据库SQL，创建一张简单的用户表：123456789-- DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `userName` varchar(255) DEFAULT NULL, `password` varchar(255) DEFAULT NULL, `createTime` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP, `lastUpdateTime` datetime DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP, `userId` int(11) NOT NULL AUTO_INCREMENT, PRIMARY KEY (`userId`)) ENGINE=InnoDB AUTO_INCREMENT=13 DEFAULT CHARSET=utf8; pom.xml文件配置（依赖部分）1234567891011121314151617181920212223242526272829303132333435363738394041424344 &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.22&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- mybatis generator 自动生成代码插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建mybatisGenerator.xml配置文件。安装插件后可以在resource-&gt;new中看到 ‘mybatis-generator-config’，生成即可。 （这里如果没有默认起名为mybatisGenerator.xml，启动maven时会报错）。生成后修改文件，具体内容如下。123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC \"-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN\" \"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd\" &gt;&lt;generatorConfiguration&gt; &lt;!-- !!!! Driver Class Path !!!! --&gt; &lt;!-- mysql驱动jar包路径 --&gt; &lt;classPathEntry location=\":/Files/repository/mysql/mysql-connector-java/5.1.38/mysql-connector-java-5.1.38.jar\"/&gt; &lt;context id=\"context\" targetRuntime=\"MyBatis3\"&gt; &lt;commentGenerator&gt; &lt;property name=\"suppressAllComments\" value=\"false\"/&gt; &lt;property name=\"suppressDate\" value=\"true\"/&gt; &lt;/commentGenerator&gt; &lt;!-- !!!! Database Configurations !!!! --&gt; &lt;!-- 数据库驱动和连接配置 --&gt; &lt;jdbcConnection driverClass=\"com.mysql.jdbc.Driver\" connectionURL=\"jdbc:mysql://localhost/mystudy\" userId=\"root\" password=\"123456\"/&gt; &lt;javaTypeResolver&gt; &lt;property name=\"forceBigDecimals\" value=\"false\"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- !!!! Model Configurations !!!! --&gt; &lt;javaModelGenerator targetPackage=\"generator.model\" targetProject=\"src/main/java/mybatis\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;property name=\"trimStrings\" value=\"true\"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- !!!! Mapper XML Configurations !!!! --&gt; &lt;sqlMapGenerator targetPackage=\"generator.mapping\" targetProject=\"src/main/java/mybatis\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- !!!! Mapper Interface Configurations !!!! --&gt; &lt;javaClientGenerator targetPackage=\"generator.dao\" targetProject=\"src/main/java/mybatis\" type=\"XMLMAPPER\"&gt; &lt;property name=\"enableSubPackages\" value=\"true\"/&gt; &lt;/javaClientGenerator&gt; &lt;!-- !!!! Table Configurations !!!! --&gt; &lt;!-- 设置数据库表名 --&gt; &lt;table tableName=\"user\" enableCountByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"false\" enableUpdateByExample=\"false\"/&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 配置maven启动项mybatis-generator:generate -e 自动生成前的目录结构 自动生成后的目录结构 So easy，and 强大的不行~ 以后如果增加数据库表的字段，重新自动生成一下代码就好了。但是如果在表中改字段名，或是有其他关联操作，就不好说了。所以在工程中最好把自动生成的代码单独拎出一份，其他业务需求的实现放在其他文件中，尽量互不影响。","categories":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/categories/JavaWeb/"}],"tags":[{"name":"Web","slug":"Web","permalink":"http://yoursite.com/tags/Web/"},{"name":"mybatis","slug":"mybatis","permalink":"http://yoursite.com/tags/mybatis/"}]},{"title":"SSM框架基本配置","slug":"ssm1","date":"2017-05-11T11:03:45.000Z","updated":"2018-06-29T11:42:08.786Z","comments":true,"path":"2017/05/11/ssm1/","link":"","permalink":"http://yoursite.com/2017/05/11/ssm1/","excerpt":"下载项目源码：$ git clone git@github.com:rayeden/xssm.git","text":"下载项目源码：$ git clone git@github.com:rayeden/xssm.git SSM框架基本配置1、新建一个idea的maven工程新建idea Projec -&gt; maven -&gt; 一路next 工程结构如下，分层含义： action dao exception service so vo 执行层 数据交互层 异常 业务层 入参 出参 如下图建立工程结构 2、用户登录示例时序图 业务逻辑很简单，用户发起一个登录请求，传递用户名和密码到服务端后台，后台由Service层接受请求后进行业务处理，发送给dao层进行数据交互处理，dao层由mybatis的配置文件直接和数据库进行交互，获取数据库数据，把结果返回给Service。 3、数据库建表CREATE DATABASE xssm; DROP TABLE IF EXISTS user; CREATE TABLE user( id INT NOT NULL AUTO_INCREMENT, userName VARCHAR(255) NOT NULL, password VARCHAR(255) NOT NULL, createTime DATE NOT NULL, PRIMARY KEY(id) )ENGINE=InnoDB DEFAULT CHARSET=utf8; 4、pom文件配置仅仅是搭建一个简单的SSM框架这些配置就够。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.xhtc.ssm&lt;/groupId&gt; &lt;artifactId&gt;ssm&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;spring.version&gt;4.2.5.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.4.2&lt;/mybatis.version&gt; &lt;mysql.version&gt;5.1.38&lt;/mysql.version&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;javax.servlet.version&gt;3.0.1&lt;/javax.servlet.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring framework--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 数据库配置--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp2&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;$&#123;javax.servlet.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 5、创建属性配置文件jdbc.property此文件将被Spring配置文件引用，作为mysql的连接信息。1234567891011driver=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/xssm?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true&amp;allowMultiQueries=trueusername=rootpassword=123456#定义初始连接数initialSize=0#定义最大空闲maxIdle=20#定义最小空闲minIdle=1 6、Spring和mybatis配置文件我习惯把配置文件分的比较细，这样后续项目扩大后结构更清晰。 applicationContext.xml12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 引入属性文件 --&gt; &lt;context:property-placeholder location=&quot;classpath*:properties/jdbc.properties&quot;/&gt; &lt;!-- 配置自动注入注解 --&gt; &lt;context:annotation-config/&gt; &lt;!-- 自动扫描bean --&gt; &lt;context:component-scan base-package=&quot;com.xhtc.xssm&quot;/&gt; &lt;!-- 配置mysql数据库连接池 --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp2.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;driver&#125;&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot;/&gt; &lt;!-- 初始化连接大小 --&gt; &lt;property name=&quot;initialSize&quot; value=&quot;$&#123;initialSize&#125;&quot;/&gt; &lt;!-- 连接池最大空闲 --&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;$&#123;maxIdle&#125;&quot;/&gt; &lt;!-- 连接池最小空闲 --&gt; &lt;property name=&quot;minIdle&quot; value=&quot;$&#123;minIdle&#125;&quot;/&gt; &lt;/bean&gt; &lt;!-- 配置事务管理 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; applicationContext-mvc.xml1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt; &lt;!-- 配置注解驱动 --&gt; &lt;mvc:annotation-driven/&gt; &lt;/beans&gt; applicationContext-mybatis.xml1234567891011121314151617181920&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!-- 配置mybatis --&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!-- 自动扫描mapping.xml文件 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath*:mybatis/mapper/UserDao.xml&quot;/&gt; &lt;!-- mysql配置文件路径 --&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis/mybatis-config.xml&quot;/&gt; &lt;/bean&gt; &lt;!-- DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;bean id=&quot;mapperScannerConfigurer&quot; class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.xhtc.xssm.dao&quot;/&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; mybatis-config.xmlmybatis很强大，但是这里我们只为了把应用跑起来，啥都不配也没事～12345&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt;&lt;/configuration&gt; 7、代码在完成整个工程的构思和设计之后，可以先把接口写好。 先写接口UserDao.java12345678public interface UserDao &#123; int isUserExist(String userName); void createUser(UserSO userSO); UserVO getUser(String userName);&#125; UserService.java123456public interface UserService &#123; void register(UserSO userSO); UserVO getUser(UserSO userSO);&#125; 入参出参每个action的出参入参，根据具体业务需求设计，一般对应数据库字段。12345678public class UserSO &#123; private String userName; private String password;ß (... Getters and Setters)&#125; 12345678910111213141516171819public class UserVO &#123; private String userName; private String password; private String createTime; (... Getters and Setters) //打印出参 public String toString()&#123; StringBuilder sb = new StringBuilder(); sb.append(\"UserVO: [username = \" + userName + \",\"); sb.append(\"password = \" + password + \",\"); sb.append(\"createTime = \" + createTime); sb.append(\"]\"); return sb.toString();&#125; 实现接口别忘了添加注解，让Spring自动注入bean。 Action层1234567891011121314@Controllerpublic class UserAction &#123; @Autowired private UserService userService; public void register(UserSO userSO)&#123; userService.register(userSO); &#125; public UserVO getUser(UserSO userSO)&#123; return userService.getUser(userSO); &#125;&#125; Service层12345678910111213141516171819202122232425@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserDao userDao; public void register(UserSO userSO) &#123; try&#123; if(userDao.isUserExist(userSO.getUserName()) == 1) &#123; throw new UserExistException(\"用户已存在\"); &#125; &#125;catch (UserExistException e)&#123; System.out.println(e); &#125; userDao.createUser(userSO); &#125; public UserVO getUser(UserSO userSO) &#123; UserVO user = userDao.getUser(userSO.getUserName()); if(null == user)&#123; throw new UserNotExistException(\"用户不存在\"); &#125; return user; &#125;&#125; Dao层 – UserDao.xmlDao层不需要代码，直接用对应类名的mybatis的配置文件实现和数据库的交互。12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.xhtc.xssm.dao.UserDao&quot;&gt; &lt;insert id=&quot;createUser&quot; parameterType=&quot;com.xhtc.xssm.so.UserSO&quot;&gt; INSERT INTO user ( userName, password, createTime ) VALUES ( #&#123;userName, jdbcType=VARCHAR&#125;, #&#123;password, jdbcType=VARCHAR&#125;, SYSDATE() ) &lt;/insert&gt; &lt;select id=&quot;isUserExist&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;java.lang.Integer&quot;&gt; SELECT count(1) FROM user WHERE userName = #&#123;userName&#125; &lt;/select&gt; &lt;select id=&quot;getUser&quot; parameterType=&quot;java.lang.String&quot; resultType=&quot;com.xhtc.xssm.vo.UserVO&quot;&gt; SELECT userName, password, createTime From user Where userName = #&#123;userName&#125; &lt;/select&gt; &lt;/mapper&gt; 异常类这个项目的逻辑很简单，我设置了两个异常。1、用户登录时发现用户名重复，抛出用户已存在的异常。1234567891011121314151617181920212223242526272829public class UserExistException extends RuntimeException &#123; private String code ; //异常对应的返回码 private String msg; //异常对应的描述信息 public UserExistException() &#123; super(); &#125; public UserExistException(String message) &#123; super(message); msg = message; &#125; public UserExistException(String code, String msg) &#123; super(); this.code = code; this.msg = msg; &#125; public String getRetCd() &#123; return code; &#125; public String getMsgDes() &#123; return msg; &#125;&#125; 2、获取用户时，如果用户不存在就抛出用户不存在的异常。12345678910111213141516171819202122232425262728public class UserNotExistException extends RuntimeException &#123; private String code ; //异常对应的返回码 private String msg; //异常对应的描述信息 public UserNotExistException() &#123; super(); &#125; public UserNotExistException(String message) &#123; super(message); msg = message; &#125; public UserNotExistException(String code, String msg) &#123; super(); this.code = code; this.msg = msg; &#125; public String getRetCd() &#123; return code; &#125; public String getMsgDes() &#123; return msg; &#125;&#125; 单元测试简单暴力的JUnit单元测试。123456789101112131415161718192021222324252627282930@RunWith(SpringJUnit4ClassRunner.class)//配置所有Spring文件@ContextConfiguration(&#123;&quot;classpath:spring/applicationContext*.xml&quot;&#125;)public class UserTest &#123; @Autowired private UserAction userAction; //运行成功后可在数据库中查看用户信息（用户名，密码，创建时间） //如果重复注册，会抛出“用户已存在”的异常信息 @Test public void testUserRegister()&#123; UserSO userSO = new UserSO(); userSO.setUserName(&quot;xhtc111&quot;); userSO.setPassword(&quot;123456&quot;); userAction.register(userSO); System.out.println(&quot;---------------------&quot;); &#125; //运行成功后，可以看到控制台打印出了用户信息（用户名，密码，创建时间） //如果用户不存在，会抛出“用户不存在”的异常信息 @Test public void testGetUser()&#123; UserSO userSO = new UserSO(); userSO.setUserName(&quot;xhtc111&quot;); UserVO user = userAction.getUser(userSO); System.out.println(&quot;---------------------&quot;); System.out.println(user.toString()); &#125;&#125; 8、总结这是最简单的SSM框架配置，仅此做一个示例记录。 Spring框架文档：《spring-framework-reference》（这个有点长，要慢慢看。） mybatis学习文档：《Java Persistence with MyBatis 3》（非常推荐这个文档，100多页，英文版通俗易懂，一两天就可以看完，掌握mybatis的基本用法～）","categories":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"http://yoursite.com/categories/JavaWeb/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/tags/Java/"},{"name":"Web","slug":"Web","permalink":"http://yoursite.com/tags/Web/"},{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/tags/Spring/"}]},{"title":"决策树","slug":"决策树","date":"2016-09-14T05:45:32.000Z","updated":"2018-06-29T11:42:08.785Z","comments":true,"path":"2016/09/14/决策树/","link":"","permalink":"http://yoursite.com/2016/09/14/决策树/","excerpt":"","text":"Purpose分类(ID3)。 Data最后一列为数据标签 不浮出水面是否可以生存 是否有脚蹼 是否鱼类 1 Y Y Y 2 Y Y Y 3 Y N N 4 N Y N 5 N Y N Process &amp; Code信息增益计算信息增益(Information Gain)，熵越大信息增益越高。香农熵: 集合信息的度量方式,定义为信息的期望值。公式(其中p(xi)是选择该分类的概率):$$l(x_i)=-log_2p(x_i)$$ 计算熵: 需要计算所有类别所有可能只包含的信息期望值$$H=-\\sum_{i=1}^{n}p(x_i)log_2p(x_i)$$123456789101112131415161718# 计算香农熵def calcShannoEntropy(dataSet): numEntries = len(dataSet) labelCounts = &#123;&#125; # 遍历数据集中的特征,把特征名称和出现次数保存在字典中 for featVec in dataSet: # 最后一列为数据标签 currentLabel = featVec[-1] if currentLabel not in labelCounts.keys():labelCounts[currentLabel] = 0 labelCounts[currentLabel] += 1 shannonEntropy = 0.0 for key in labelCounts: # 特征在总体数据中出现的概率 prob = float(labelCounts[key])/numEntries # 根据公式计算熵 shannonEntropy -= prob * log(prob, 2) # log base 2 return shannonEntropy 熵值越大，则混合的数据也越多(分类多，数据复杂)。 划分数据集对每个特征划分数据集的结果计算一次信息熵，然后判断按照哪个特征划分数据集是最好的方式。1234567891011# 参数: 待划分的数据集，划分数据集的特征，特征返回值def splitDataSet(dataSet, axis, value): retDataSet = [] # 遍历数据集 for featVec in dataSet: # 找到符合要求的元素就抽取出来 if featVec[axis] == value: reducedFeatVec = featVec[:axis] reducedFeatVec.extend(featVec[axis+1:]) retDataSet.append(reducedFeatVec) return retDataSet 选取最好的数据集划分方式12345678910111213141516171819202122232425262728def chooseBestFeatureToSplit(dataSet): # 最后一列为标签，特征数=总长度-1 numFeature = len(dataSet[0]) - 1 # 总体样本的熵 baseEntropy = calcShannoEntropy(dataSet) # 初始化信息增益变量 bestInfoGain = 0.0 # 最好的划分数据集的特征 bestFeature = -1 for i in range(numFeature): # 取出当前特征所在的列 featList = [example[i] for example in dataSet] # 把当前特征可能的特征值存到set中(唯一的) uniqueVals = set(featList) newEntropy = 0.0 for value in uniqueVals: # 获取当前特征和数据标签相符合的子数据集 subDataSet = splitDataSet(dataSet, i, value) # 计算特征出现的概率 prob = len(subDataSet)/float(len(dataSet)) # 计算该特征划分下子数据集的熵 newEntropy += prob * calcShannoEntropy(subDataSet) infoGain = baseEntropy - newEntropy # 取到子数据集中熵最大的划分特征 if(infoGain &gt; bestInfoGain): bestInfoGain = infoGain bestFeature = i return bestFeature Adv &amp; DisAdv决策树优点:计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。 决策树缺点:可能产生过度匹配。 适用数据类型数值型和标称型。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"机器学习实战","slug":"机器学习实战","permalink":"http://yoursite.com/tags/机器学习实战/"},{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"kNN改进约会匹配","slug":"kNN改进约会匹配","date":"2016-09-12T10:52:07.000Z","updated":"2018-06-29T11:42:08.784Z","comments":true,"path":"2016/09/12/kNN改进约会匹配/","link":"","permalink":"http://yoursite.com/2016/09/12/kNN改进约会匹配/","excerpt":"","text":"Purpose使用KNN算法对约会对象的数据进行分类和预测。 Process 先用python处理文本文件，转换成分类器可识别的数据类型。 归一化数值，减少数值对计算结果的影响。 验证分类器。 Data数据集有四列，分别为(约会对象的) 每年获得的飞行常客里程数 玩视频游戏所耗时间的百分比 每周消费的冰淇淋总公升数 适合程度(可下载《机器学习实战》源码数据) Code准备数据:从文本文件中解析数据123456789101112131415161718192021222324252627282930313233343536# 把文本文件转换成矩阵from numpy import *def file2matrix(filename): fr = open(filename) numberOfLines = len(fr.readlines()) # 创建对应大小的空矩阵 returnMat = zeros((numberOfLines,3)) classLabelVector=[] fr = open(filename) index = 0 # 逐行读取 for line in fr.readlines(): line = line.strip() listFromLine = line.split('\\t') # 根据'\\t'把每行数据处理成列表元素(仅处理前三列) returnMat[index,:] = listFromLine[0:3] # 最后一列为好感度，根据字符串内容转换成数值 if cmp(listFromLine[-1],'didntLike') == 0: classLabelVector.append(1) elif cmp(listFromLine[-1],'smallDoses') == 0: classLabelVector.append(2) elif cmp(listFromLine[-1],'largeDoses') == 0: classLabelVector.append(3) # 此处仅为datingTestSet2.txt准备 else: classLabelVector.append(listFromLine[-1]) index += 1 fr.close() return returnMat,classLabelVector# 保证datingTestSet.txt在相应目录下datingDataMat,datingLabels = file2matrix('datingTestSet.txt')print datingDataMat# 对约会对象的好感度print datingLabels 分析数据:使用Matplotlib创建散点图12345678910import matplotlib.pyplot as pltfig = plt.figure# 二维图表(只能选取两列数据)ax = fig.add_subplot(111)# 显示以数据中的第2列和第3列分别作为x轴和y轴的散点图(没有样本类别标签)# ax.scatter(datingDataMat[:,1],datingDataMat[:,2])# 带样本标签的散点图(以颜色区分标签)ax.scatter(datingDataMat[:,1],datingDataMat[:,2],15.0*array(datingLabels),15.0*array(datingLabels))plt.show 准备数据:归一化特征值123456789101112# 数据集中的里程数远远大于其他数据# 用 maxValue = (oldValue-min)/(max-min)这个公式把数值控制在(0,1)def autoNorm(dataSet): minVals = dataSet.min(0) maxVals = dataSet.max(0) ranges = maxVals - minVals m = dataSet.shape[0] normDataSet = dataSet - tile(minVals, (m,1)) normDataSet = normDataSet/tile(ranges, (m,1)) return normDataSet, ranges, minValsnormMat,ranges,minVals = autoNorm(datingDataMat) 测试算法:作为完整程序验证分类器123456789101112131415161718192021def datingClassTest(): # 90%数据作为训练样本，%10数据测试分类器 hoRatio = 0.1 datingDataMat,datingLabels = file2matrix('datingTestSet2.txt') normMat, ranges, minVals = autoNorm(datingDataMat) # m = 1000 m = normMat.shape[0] # numTestVecs = 100 numTestVecs = int(m*hoRatio) errorCount = 0.0 # 对每一个测试数据进行验证 for i in range(numTestVecs): # 用分类器训练90%数据后测试numTestVecs[i],k=3 classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) #print \"#%d the classifier came back with: %d, the real answer is: %d \" % (i,int(classifierResult),int(datingLabels[i])) # 如果分类结果不正确，错误数+1 if (classifierResult != datingLabels[i]): errorCount += 1.0 # 得到此分类器在该数据集下的错误率 print \"the total error rate is: %f\" % (errorCount/float(numTestVecs))datingClassTest() 使用算法:构建完整可用系统12345678910111213141516def classifyPerson(): resultList = ['not at all', 'in small doses', 'in large doses'] # 输入玩视频游戏的时间 percentTats = float(raw_input(\"percentage of time spent playing video games?\")) # 输入里程数 ffMiles = float(raw_input(\"frequent flier miles earned per year?\")) # 输入冰淇淋数 iceCream = float(raw_input(\"liters of ice cream consumed per year?\")) datingDataMat, datingLabels = file2matrix('datingTestSet2.txt') normMat, ranges, minVals = autoNorm(datingDataMat) # 作为inX待预测数据 inArr = array([ffMiles, percentTats, iceCream]) classifierResult = classify0((inArr-minVals)/ranges,normMat,datingLabels,3) print \"You will probably like this person: \", resultList[int(classifierResult) - 1]classifyPerson() Adv &amp; DisAdvkNN优点:简单有效 kNN缺点:必须保存全部数据集，如果数据集很大，必须使用大量存储空间，同时需要对计算数据集中的每个数据计算距离值，非常耗时。并且kNN算法无法给出任何数据的基础结构信息，无法知晓平均实例样本和典型实例样本具体有什么特征(概率测量方法可以解决这个问题)。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"机器学习实战","slug":"机器学习实战","permalink":"http://yoursite.com/tags/机器学习实战/"},{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"kNN算法","slug":"kNN算法简单示例","date":"2016-09-11T11:03:45.000Z","updated":"2018-06-29T11:42:08.781Z","comments":true,"path":"2016/09/11/kNN算法简单示例/","link":"","permalink":"http://yoursite.com/2016/09/11/kNN算法简单示例/","excerpt":"","text":"Purpose已知数据集中N个点的二维坐标(带标签)，给出另一个点X，求出X属于数据集中的哪个标签类型。 Process 计算X到数据集中每个点的距离。 按照距离对坐标点递增排序。 选取和X最近的k个坐标点。 确定这前k个点的类别的出现频率。 返回频率最高的类别作为X的预测分类。Scipy Lecture Notes Code12345678910111213141516171819202122232425262728293031323334# 创建数据集和对应标签from numpy import *import operatordef createDataSet(): group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]]) labels = ['A','A','B','B'] return group, labelsdef classify0(inX, dataSet, labels, k): # 获取dataSet维度 dataSetSize = dataSet.shape[0] # 把X的坐标分别减去数据集中的坐标，获得水平和垂直的距离 diffMat = tile(inX, (dataSetSize,1)) - dataSet # 勾股定理，水平和垂直距离的平方相加，然后根号求出斜边长度，即两点距离 sqDiffMat = diffMat ** 2 sqDistances = sqDiffMat.sum(axis=1) distance = sqDistances ** 0.5 # 对distance距离(向量)进行排序 sortedDistIndicies = distance.argsort() # 创建字典 classCount=&#123;&#125; # 遍历排序被排序的向量，对前k个距离X最近的点做map映射 for i in range(k): voteIlabel = labels[sortedDistIndicies[i]] classCount[voteIlabel] = classCount.get(voteIlabel,0)+1 # 根据标签出现的次数作为关键字排序(key) sortedClassCount = sorted(classCount.iteritems(),key=operator.itemgetter(1),reverse=True) # 获得出现次数最多的标签作为X的预测分类 return sortedClassCount[0][0]group,labels = createDataSet()result = classify0([0,0],group,labels,3) # Bresult = classify0([1,2],group,labels,3) # A","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/categories/机器学习/"}],"tags":[{"name":"机器学习实战","slug":"机器学习实战","permalink":"http://yoursite.com/tags/机器学习实战/"},{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Java模拟JVM堆","slug":"Java模拟JVM堆","date":"2016-09-11T04:34:10.000Z","updated":"2018-06-29T11:42:08.780Z","comments":true,"path":"2016/09/11/Java模拟JVM堆/","link":"","permalink":"http://yoursite.com/2016/09/11/Java模拟JVM堆/","excerpt":"","text":"Purpose用Java程序模拟JVM的堆内存结构，并实现两个方法： 实现建一个新对象后堆内存的分配过程。 实现垃圾回收过程(分代)。 Process 新生代可以分为Eden，SurvivorFrom，SurvivorTo，复制算法。老年代仅为Old区。 新建一个对象后需要先获得该对象的大小，然后在新生代中查找相应大小的连续空间。 如果新生代无法分配，则检查空间分配担保策略是否开启。如果不允许担保，则直接进行FullGC。 如果允许担保，则检查老年代的空闲空间是否符合担保要求，如果符合则进行MinorGC，不符合则进行FullGC。 Code(TODO)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class MyHeap &#123; //eden区大小为8m byte[] eden = new byte[1024 * 1024 * 8]; //survivor From和To区分别都为1m byte[] sFrom = new byte[1024 * 1024]; byte[] sTo = new byte[1024 * 1024]; //old(老年代)区为100m byte[] old = new byte[1024 * 1024 * 100]; public void allocation(Object obj)&#123; //TODO 计算出obj的大小 int objectSpace; //检查Eden区是否有足够的连续空间分配该对象 boolean isEnoughSpace = isEnoughSpace(eden + sFrom + sTo, objectSpace); if(isEnoughSpace)&#123; minorGC(); &#125;else&#123; //如果没有足够空间，则查看空间分配担保情况 boolean alllcationGuarantee; //允许担保 if(alllcationGuarantee)&#123; //新生代全部存活对象所占的空间 int aliveObject = aliveObjectCount(); //老年代是否有足够的连续空间分配 boolean isOldHasEnoughSpace = isEnoughSpace(old, aliveObject * objectSpace); if(isOldHasEnoughSpace)&#123; minorGC(); &#125;else&#123; fullGC(); &#125; &#125;else&#123; fullGC(); &#125; &#125; &#125;//TODO public int aliveObjectCount()&#123; return null; &#125; public boolean isEnoughSpace(byte[] area, int needSpace)&#123;&#125; public void minorGC()&#123;&#125; public void fullGC()&#123;&#125;&#125; 先记下问题和思路，待完善。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[]}]}